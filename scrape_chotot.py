import os
import json
import time
import requests
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# --- C·∫§U H√åNH ---
BASE_URL = "https://www.chotot.com"
START_URL = "https://www.chotot.com/mua-ban-nhac-cu-ha-noi?price=0-2100000&f=p&limit=20"
SHEET_ID = "14tqKftTqlesnb0NqJZU-_f1EsWWywYqO36NiuDdmaTo"
SHEET_NAME = "Ch·ª£ t·ªët"

def get_telegram_config():
    return {
        "token": os.environ.get("TELEGRAM_BOT_TOKEN"),
        "chat_id": os.environ.get("TELEGRAM_CHAT_ID")
    }

def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # Ch·∫°y ng·∫ßm
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    # Fake User-Agent ƒë·ªÉ tr√°nh b·ªã ch·∫∑n
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def connect_google_sheet():
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = json.loads(os.environ.get("GOOGLE_CREDENTIALS"))
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_json, scope)
    client = gspread.authorize(creds)
    
    sh = client.open_by_key(SHEET_ID)
    try:
        worksheet = sh.worksheet(SHEET_NAME)
    except gspread.WorksheetNotFound:
        # T·∫°o sheet m·ªõi n·∫øu ch∆∞a c√≥
        worksheet = sh.add_worksheet(title=SHEET_NAME, rows="1000", cols="6")
        worksheet.append_row(["Title", "Price", "Link", "Time Posted", "Location", "Scraped At"])
    
    return worksheet

def send_telegram_alert(item):
    cfg = get_telegram_config()
    if not cfg["token"] or not cfg["chat_id"]:
        return

    # Format tin nh·∫Øn HTML
    message = (
        f"üé∏ <b>H√ÄNG M·ªöI TR√äN CH·ª¢ T·ªêT!</b>\n\n"
        f"üè∑ <b>T√™n:</b> {item['title']}\n"
        f"üí∞ <b>Gi√°:</b> {item['price']}\n"
        f"üìç <b>Khu v·ª±c:</b> {item['location']}\n"
        f"‚è∞ <b>ƒêƒÉng:</b> {item['time']}\n\n"
        f"üîó <a href='{item['link']}'>Xem chi ti·∫øt ngay</a>"
    )
    
    url = f"https://api.telegram.org/bot{cfg['token']}/sendMessage"
    payload = {
        "chat_id": cfg["chat_id"],
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    try:
        requests.post(url, json=payload)
        time.sleep(1) # Tr√°nh spam
    except Exception as e:
        print(f"L·ªói g·ª≠i Telegram: {e}")

def scrape_data():
    driver = setup_driver()
    worksheet = connect_google_sheet()
    
    # L·∫•y danh s√°ch link ƒë√£ t·ªìn t·∫°i ƒë·ªÉ tr√°nh tr√πng l·∫∑p
    existing_links = set(worksheet.col_values(3)[1:]) # C·ªôt 3 l√† Link, b·ªè header
    
    new_items = []
    page = 1
    has_items = True

    while has_items:
        current_url = f"{START_URL}&page={page}" if page > 1 else START_URL
        print(f"Dang c√†o trang: {page} - {current_url}")
        driver.get(current_url)
        
        try:
            # ƒê·ª£i list items load. D·ª±a v√†o class 'a14axl8t' trong HTML b·∫°n cung c·∫•p
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "li.a14axl8t"))
            )
            
            # L·∫•y t·∫•t c·∫£ c√°c th·∫ª li l√† item
            items = driver.find_elements(By.CSS_SELECTOR, "li.a14axl8t")
            
            if not items:
                print("Kh√¥ng t√¨m th·∫•y items n√†o n·ªØa.")
                has_items = False
                break

            items_found_on_page = 0
            
            for item in items:
                try:
                    # Link
                    link_el = item.find_element(By.TAG_NAME, "a")
                    link = link_el.get_attribute("href")
                    if not link.startswith("http"):
                        link = BASE_URL + link
                    
                    # N·∫øu link ƒë√£ c√≥ trong sheet th√¨ b·ªè qua (c≈©)
                    if link in existing_items_check: # D√πng set check cho nhanh
                        continue
                        
                    existing_items_check.add(link) # Add v√†o ƒë·ªÉ loop sau ko tr√πng
                    
                    # Title (trong h3)
                    try:
                        title = item.find_element(By.CSS_SELECTOR, "h3").text
                    except:
                        title = link_el.get_attribute("title") or "No Title"

                    # Price
                    try:
                        price = item.find_element(By.CSS_SELECTOR, "span.bfe6oav").text # Class ch·ª©a gi√°
                    except:
                        price = "Th·ªèa thu·∫≠n"
                        
                    # Time
                    try:
                        time_posted = item.find_element(By.CSS_SELECTOR, "span.c1u6gyxh.tx5yyjc").text
                    except:
                        time_posted = "N/A"

                    # Location
                    try:
                        loc = item.find_element(By.CSS_SELECTOR, "span.c1u6gyxh:not(.tx5yyjc)").text
                    except:
                        loc = "H√† N·ªôi"

                    item_data = {
                        "title": title,
                        "price": price,
                        "link": link,
                        "time": time_posted,
                        "location": loc,
                        "scraped_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    
                    new_items.append(item_data)
                    items_found_on_page += 1

                except Exception as e:
                    print(f"L·ªói parse 1 item: {e}")
                    continue
            
            if items_found_on_page == 0 and page > 1:
                # N·∫øu trang n√†y ko c√≥ item m·ªõi n√†o (to√†n tr√πng), c√≥ th·ªÉ d·ª´ng s·ªõm
                # Nh∆∞ng ƒë·ªÉ ch·∫Øc ch·∫Øn, ta ch·ªâ d·ª´ng khi kh√¥ng t√¨m th·∫•y element li
                pass

            page += 1
            time.sleep(2) # Ngh·ªâ nh·∫π

        except Exception as e:
            print(f"D·ª´ng l·∫°i t·∫°i trang {page}. L√Ω do: Kh√¥ng th·∫•y list h√†ng ho·∫∑c h·∫øt trang. ({e})")
            has_items = False

    driver.quit()
    
    # X·ª≠ l√Ω d·ªØ li·ªáu m·ªõi
    if new_items:
        print(f"T√¨m th·∫•y {len(new_items)} m√≥n m·ªõi.")
        # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ m√≥n c≈© nh·∫•t trong ƒë√°m m·ªõi l√™n tr∆∞·ªõc (gi·ªØ th·ª© t·ª± th·ªùi gian)
        new_items.reverse()
        
        rows_to_add = []
        for item in new_items:
            # G·ª≠i Tele
            send_telegram_alert(item)
            # Chu·∫©n b·ªã data ghi sheet
            rows_to_add.append([
                item["title"],
                item["price"],
                item["link"],
                item["time"],
                item["location"],
                item["scraped_at"]
            ])
        
        # Ghi v√†o sheet (batch update cho nhanh)
        worksheet.append_rows(rows_to_add)
    else:
        print("Kh√¥ng c√≥ m√≥n h√†ng n√†o m·ªõi.")

# Bi·∫øn t·∫°m ƒë·ªÉ check duplicate trong runtime
existing_items_check = set()

if __name__ == "__main__":
    # Load l·∫°i existing links t·ª´ sheet v√†o set tr∆∞·ªõc khi ch·∫°y
    try:
        ws = connect_google_sheet()
        existing_items_check = set(ws.col_values(3)[1:])
    except:
        pass
        
    scrape_data()
