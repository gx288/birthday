import os
import json
import time
import requests
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime

# --- C·∫§U H√åNH ---
BASE_URL = "https://www.chotot.com"
START_URL = "https://www.chotot.com/mua-ban-nhac-cu-ha-noi?price=0-2100000&f=p&limit=20"
SHEET_ID = "14tqKftTqlesnb0NqJZU-_f1EsWWywYqO36NiuDdmaTo"
SHEET_NAME = "Ch·ª£ t·ªët"

def log(message):
    """In log k√®m th·ªùi gian"""
    now = datetime.now().strftime("%H:%M:%S")
    print(f"[{now}] {message}")

def get_telegram_config():
    return {
        "token": os.environ.get("TELEGRAM_BOT_TOKEN"),
        "chat_id": os.environ.get("TELEGRAM_CHAT_ID")
    }

def setup_driver():
    log("üåê ƒêang kh·ªüi t·∫°o tr√¨nh duy·ªát Chrome (Headless)...")
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    # User Agent gi·∫£ l·∫≠p ƒë·ªÉ kh√¥ng b·ªã ch·∫∑n
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36")
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def connect_google_sheet():
    log("üìÇ ƒêang k·∫øt n·ªëi Google Sheets...")
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = json.loads(os.environ.get("GOOGLE_CREDENTIALS"))
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_json, scope)
    client = gspread.authorize(creds)
    
    sh = client.open_by_key(SHEET_ID)
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        log(f"‚úÖ ƒê√£ t√¨m th·∫•y sheet '{SHEET_NAME}'.")
    except gspread.WorksheetNotFound:
        log(f"‚ö†Ô∏è Ch∆∞a c√≥ sheet '{SHEET_NAME}', ƒëang t·∫°o m·ªõi...")
        # T·∫°o th√™m c·ªôt Seller v√† Views
        worksheet = sh.add_worksheet(title=SHEET_NAME, rows="1000", cols="8")
        worksheet.append_row(["Title", "Price", "Link", "Time Posted", "Location", "Seller", "Views", "Scraped At"])
        log("‚úÖ ƒê√£ t·∫°o sheet m·ªõi th√†nh c√¥ng.")
    
    return worksheet

def send_telegram_alert(item):
    cfg = get_telegram_config()
    if not cfg["token"] or not cfg["chat_id"]:
        return

    log(f"üì≤ ƒêang g·ª≠i tin Telegram: {item['title']}...")
    
    message = (
        f"üé∏ <b>H√ÄNG M·ªöI TR√äN CH·ª¢ T·ªêT!</b>\n\n"
        f"üè∑ <b>{item['title']}</b>\n"
        f"üí∞ Gi√°: <b>{item['price']}</b>\n"
        f"üë§ Ng∆∞·ªùi b√°n: {item['seller']}\n"
        f"üëÄ L∆∞·ª£t xem: {item['views']}\n"
        f"üìç Khu v·ª±c: {item['location']}\n"
        f"‚è∞ ƒêƒÉng: {item['time']}\n\n"
        f"üîó <a href='{item['link']}'>üëâ Xem chi ti·∫øt t·∫°i ƒë√¢y</a>"
    )
    
    url = f"https://api.telegram.org/bot{cfg['token']}/sendMessage"
    payload = {
        "chat_id": cfg["chat_id"],
        "text": message,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    try:
        requests.post(url, json=payload)
        time.sleep(1) # Tr√°nh spam API
    except Exception as e:
        log(f"‚ùå L·ªói g·ª≠i Telegram: {e}")

def scrape_data():
    log("üöÄ B·∫ÆT ƒê·∫¶U QU√Å TR√åNH SCRAPE...")
    
    # 1. L·∫•y d·ªØ li·ªáu c≈© t·ª´ Sheet ƒë·ªÉ so s√°nh
    worksheet = connect_google_sheet()
    try:
        existing_links = worksheet.col_values(3)[1:] # C·ªôt 3 l√† Link
        existing_items_check = set(existing_links)
        log(f"‚ÑπÔ∏è ƒê√£ c√≥ {len(existing_items_check)} s·∫£n ph·∫©m trong d·ªØ li·ªáu c≈©.")
    except:
        existing_items_check = set()

    driver = setup_driver()
    new_items = []
    page = 1
    has_items = True

    while has_items:
        current_url = f"{START_URL}&page={page}" if page > 1 else START_URL
        log(f"\n--- ƒêANG X·ª¨ L√ù TRANG {page} ---")
        driver.get(current_url)
        
        try:
            # CHECK QUAN TR·ªåNG: Ki·ªÉm tra xem c√≥ th√¥ng b√°o h·∫øt k·∫øt qu·∫£ kh√¥ng
            # T√¨m text "Kh√¥ng c√≥ k·∫øt qu·∫£" trong body
            try:
                body_text = driver.find_element(By.TAG_NAME, "body").text
                if "Kh√¥ng c√≥ k·∫øt qu·∫£ cho b·ªô l·ªçc ƒë√£ ch·ªçn" in body_text:
                    log("üõë Ph√°t hi·ªán th√¥ng b√°o: 'Kh√¥ng c√≥ k·∫øt qu·∫£ cho b·ªô l·ªçc ƒë√£ ch·ªçn'.")
                    log("üõë D·ª´ng c√†o d·ªØ li·ªáu t·∫°i ƒë√¢y (b·ªè qua qu·∫£ng c√°o).")
                    has_items = False
                    break
            except:
                pass

            # ƒê·ª£i item list load
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "li.a14axl8t"))
            )
            
            items = driver.find_elements(By.CSS_SELECTOR, "li.a14axl8t")
            if not items:
                log("üõë Kh√¥ng t√¨m th·∫•y danh s√°ch s·∫£n ph·∫©m.")
                break
            
            log(f"üîé Qu√©t th·∫•y {len(items)} items tr√™n trang n√†y.")
            items_found_on_page = 0
            
            for item in items:
                try:
                    # L·∫•y Link tr∆∞·ªõc ƒë·ªÉ check tr√πng
                    link_el = item.find_element(By.TAG_NAME, "a")
                    link = link_el.get_attribute("href")
                    if not link.startswith("http"):
                        link = BASE_URL + link
                    
                    if link in existing_items_check:
                        continue # B·ªè qua n·∫øu ƒë√£ c√≥
                    
                    existing_items_check.add(link)

                    # --- TR√çCH XU·∫§T D·ªÆ LI·ªÜU ---
                    # 1. Ti√™u ƒë·ªÅ
                    try:
                        title = item.find_element(By.CSS_SELECTOR, "h3").text
                    except: title = "No Title"

                    # 2. Gi√°
                    try:
                        price = item.find_element(By.CSS_SELECTOR, "span.bfe6oav").text
                    except: price = "Th·ªèa thu·∫≠n"
                        
                    # 3. Th·ªùi gian ƒëƒÉng (c·∫≠p nh·∫≠t selector ch√≠nh x√°c h∆°n t·ª´ HTML b·∫°n cung c·∫•p)
                    try:
                        time_posted = item.find_element(By.CSS_SELECTOR, "span.c1u6gyxh.tx5yyjc").text
                    except: time_posted = "N/A"

                    # 4. Khu v·ª±c
                    try:
                        loc = item.find_element(By.CSS_SELECTOR, "span.c1u6gyxh:not(.tx5yyjc)").text
                    except: loc = "H√† N·ªôi"

                    # 5. Ng∆∞·ªùi b√°n (M·ªõi) - Class l·∫•y t·ª´ HTML: div.dteznpi span.brnpcl3
                    try:
                        seller = item.find_element(By.CSS_SELECTOR, "div.dteznpi span.brnpcl3").text
                    except: seller = "Ng∆∞·ªùi b√°n ·∫©n danh"

                    # 6. L∆∞·ª£t xem (M·ªõi) - Class l·∫•y t·ª´ HTML: div.vglk6qt span
                    try:
                        views = item.find_element(By.CSS_SELECTOR, "div.vglk6qt span").text
                    except: views = "0"

                    item_data = {
                        "title": title,
                        "price": price,
                        "link": link,
                        "time": time_posted,
                        "location": loc,
                        "seller": seller,
                        "views": views,
                        "scraped_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    }
                    
                    new_items.append(item_data)
                    items_found_on_page += 1
                    log(f"   ‚úÖ M·ªõi: {title} | {price} | {seller}")

                except Exception as e:
                    continue
            
            if items_found_on_page == 0:
                log("‚ö†Ô∏è Trang n√†y kh√¥ng c√≥ m√≥n n√†o m·ªõi (to√†n tr√πng l·∫∑p).")
                # V·∫´n ti·∫øp t·ª•c ch·∫°y sang trang sau ƒë·ªÅ ph√≤ng c√≥ tin m·ªõi b·ªã tr√¥i, 
                # tr·ª´ khi g·∫∑p th√¥ng b√°o "Kh√¥ng c√≥ k·∫øt qu·∫£" ·ªü tr√™n.

            page += 1
            time.sleep(2)

        except Exception as e:
            log(f"üõë L·ªói ho·∫∑c h·∫øt trang: {e}")
            has_items = False

    driver.quit()
    
    # --- L∆ØU V√Ä TH√îNG B√ÅO ---
    if new_items:
        log(f"üéâ T·ªïng c·ªông t√¨m th·∫•y {len(new_items)} m√≥n h√†ng M·ªöI.")
        new_items.reverse() # ƒê·∫£o ng∆∞·ª£c ƒë·ªÉ tin c≈© h∆°n trong ƒë√°m m·ªõi ƒë∆∞·ª£c l∆∞u tr∆∞·ªõc
        
        rows_to_add = []
        for item in new_items:
            # G·ª≠i Tele tin m·ªõi
            send_telegram_alert(item)
            
            # Chu·∫©n b·ªã d√≤ng cho Sheet
            rows_to_add.append([
                item["title"],
                item["price"],
                item["link"],
                item["time"],
                item["location"],
                item["seller"],
                item["views"],
                item["scraped_at"]
            ])
        
        log("üíæ ƒêang l∆∞u d·ªØ li·ªáu v√†o Sheet...")
        try:
            worksheet.append_rows(rows_to_add)
            log("‚úÖ L∆∞u th√†nh c√¥ng.")
        except Exception as e:
            log(f"‚ùå L·ªói l∆∞u Sheet: {e}")
    else:
        log("üí§ Kh√¥ng c√≥ tin m·ªõi n√†o ƒë·ªÉ th√¥ng b√°o.")

if __name__ == "__main__":
    scrape_data()
