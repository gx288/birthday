import os
import json
import time
import requests
import gspread
import random
import re
from oauth2client.service_account import ServiceAccountCredentials
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from datetime import datetime
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Cáº¤U HÃŒNH
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_URL = "https://www.chotot.com"
START_URL = "https://www.chotot.com/mua-ban-nhac-cu-ha-noi?price=0-2100000&f=p&limit=20"
SHEET_ID = "14tqKftTqlesnb0NqJZU-_f1EsWWywYqO36NiuDdmaTo"
SHEET_NAME = "Chá»£ tá»‘t"
MAX_PAGES = 12
MAX_CONSECUTIVE_EMPTY = 3
SLEEP_BETWEEN_PAGES = 4.5
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
]

HEADERS = ["STT", "Title", "Price", "Link", "Time Posted", "Location", "Seller", "Views", "Hidden"]

def log(message):
    now = datetime.now().strftime("%H:%M:%S")
    print(f"[{now}] {message}")

def get_telegram_config():
    return {
        "token": os.environ.get("TELEGRAM_BOT_TOKEN"),
        "chat_id": os.environ.get("TELEGRAM_CHAT_ID")
    }

def setup_driver():
    log("Khá»Ÿi táº¡o Chrome headless...")
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument(f"user-agent={random.choice(USER_AGENTS)}")
    driver = webdriver.Chrome(options=options)
    return driver

def connect_google_sheet():
    log("Káº¿t ná»‘i Google Sheets...")
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json_str = os.environ.get("GOOGLE_CREDENTIALS")
    if not creds_json_str:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y GOOGLE_CREDENTIALS")
    
    creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(creds_json_str), scope)
    client = gspread.authorize(creds)
    sh = client.open_by_key(SHEET_ID)
    
    try:
        worksheet = sh.worksheet(SHEET_NAME)
        log(f"TÃ¬m tháº¥y sheet: {SHEET_NAME}")
    except gspread.WorksheetNotFound:
        worksheet = sh.add_worksheet(title=SHEET_NAME, rows=2000, cols=10)
        worksheet.append_row(HEADERS)
        log("Táº¡o sheet & header má»›i")
    
    # Äáº£m báº£o header Ä‘Ãºng vÃ  Ä‘á»§ cá»™t
    current_headers = worksheet.row_values(1)
    if current_headers != HEADERS:
        worksheet.update("A1:I1", [HEADERS])
        log("ÄÃ£ cáº­p nháº­t header chuáº©n")
    if worksheet.col_count < len(HEADERS):
        worksheet.resize(cols=len(HEADERS))
    return worksheet

def get_images_from_detail(link):
    headers = {"User-Agent": random.choice(USER_AGENTS)}
    try:
        resp = requests.get(link, headers=headers, timeout=12)
        if resp.status_code != 200:
            log(f"Detail {link} status {resp.status_code}")
            return []
        
        soup = BeautifulSoup(resp.text, "html.parser")
        images = set()
        # JSON-LD
        for tag in soup.find_all("script", type="application/ld+json"):
            try:
                data = json.loads(tag.string or "{}")
                if isinstance(data, dict) and "image" in data:
                    img_val = data["image"]
                    if isinstance(img_val, str) and "cdn.chotot.com" in img_val:
                        images.add(img_val)
                    elif isinstance(img_val, list):
                        images.update([i for i in img_val if isinstance(i, str) and "cdn.chotot.com" in i])
            except:
                pass
        # Regex trong script
        for script in soup.find_all("script"):
            text = script.string or ""
            if "cdn.chotot.com" in text:
                matches = re.findall(r'(https?://cdn.chotot.com/[^"\'\s]+?.(?:jpg|jpeg|png|webp))', text)
                for m in matches:
                    if re.search(r'-\d{15,}.(jpg|jpeg|png|webp)$', m):
                        images.add(m)
        real_images = sorted(list(images))[:6]
        log(f"Láº¥y {len(real_images)} áº£nh tá»« detail {link}")
        return real_images
    except Exception as e:
        log(f"Lá»—i láº¥y áº£nh {link}: {e}")
        return []

def send_telegram_with_media(item, images):
    cfg = get_telegram_config()
    if not cfg["token"] or not cfg["chat_id"]:
        return
    
    caption = (
        f"ğŸ¸ <b>HÃ€NG Má»šI - CHá»¢ Tá»T</b>\n\n"
        f"<b>{item['title']}</b>\n"
        f"ğŸ’° <b>{item['price']}</b>\n"
        f"ğŸ‘¤ {item['seller']}\n"
        f"ğŸ‘€ {item['views']} views\n"
        f"ğŸ“ {item['location']}\n"
        f"â° {item['time']}\n\n"
        f"<a href='{item['link']}'>ğŸ”— Xem chi tiáº¿t</a>"
    )
    media_group = []
    for idx, img_url in enumerate(images):
        media_group.append({
            "type": "photo",
            "media": img_url,
            "caption": caption if idx == 0 else "",
            "parse_mode": "HTML"
        })
    if media_group:
        url = f"https://api.telegram.org/bot{cfg['token']}/sendMediaGroup"
        payload = {"chat_id": cfg["chat_id"], "media": json.dumps(media_group)}
        try:
            requests.post(url, data=payload, timeout=20)
            log(f"ÄÃ£ gá»­i album {len(images)} áº£nh cho tin má»›i: {item['title']}")
        except Exception as e:
            log(f"Lá»—i gá»­i media group: {e}")
    else:
        send_telegram_alert(item)

def send_telegram_alert(item):
    cfg = get_telegram_config()
    if not cfg["token"] or not cfg["chat_id"]:
        return
    
    message = (
        f"ğŸ¸ <b>HÃ€NG Má»šI - CHá»¢ Tá»T</b>\n\n"
        f"<b>{item['title']}</b>\n"
        f"ğŸ’° <b>{item['price']}</b>\n"
        f"ğŸ‘¤ {item['seller']}\n"
        f"ğŸ‘€ {item['views']} views\n"
        f"ğŸ“ {item['location']}\n"
        f"â° {item['time']}\n\n"
        f"<a href='{item['link']}'>ğŸ”— Xem chi tiáº¿t</a>"
    )
    requests.post(
        f"https://api.telegram.org/bot{cfg['token']}/sendMessage",
        json={"chat_id": cfg["chat_id"], "text": message, "parse_mode": "HTML"},
        timeout=10
    )

def page_has_no_results(driver):
    try:
        text = driver.find_element(By.TAG_NAME, "body").text.lower()
        return any(x in text for x in ["khÃ´ng cÃ³ káº¿t quáº£", "khÃ´ng tÃ¬m tháº¥y", "0 tin Ä‘Äƒng"])
    except:
        return False

def extract_item_data(item_element, page):
    try:
        a = item_element.find_element(By.TAG_NAME, "a")
        link = a.get_attribute("href")
        if not link.startswith("http"):
            link = BASE_URL + link.strip()
        title = item_element.find_element(By.CSS_SELECTOR, "h3").text.strip() or "KhÃ´ng cÃ³ tiÃªu Ä‘á»"
        
        price = "Thá»a thuáº­n"
        try:
            price = item_element.find_element(By.CSS_SELECTOR, "span.bfe6oav").text.strip()
        except:
            pass
        time_posted = "N/A"
        try:
            time_posted = item_element.find_element(By.CSS_SELECTOR, "span.c1u6gyxh.tx5yyjc").text.strip()
        except:
            pass
        location = "HÃ  Ná»™i"
        try:
            location = item_element.find_element(By.CSS_SELECTOR, "span.c1u6gyxh:not(.tx5yyjc)").text.strip()
        except:
            pass
        seller = "áº¨n danh"
        try:
            seller = item_element.find_element(By.CSS_SELECTOR, "div.dteznpi span.brnpcl3").text.strip()
        except:
            pass
        views_str = "0"
        try:
            views_str = item_element.find_element(By.CSS_SELECTOR, "div.vglk6qt span").text.strip()
        except:
            pass
        views = int(''.join(c for c in views_str if c.isdigit())) if ''.join(c for c in views_str if c.isdigit()) else 0
        return {
            "title": title,
            "price": price,
            "link": link,
            "time": time_posted,
            "location": location,
            "seller": seller,
            "views": views,
            "scraped_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "page": page
        }
    except:
        return None

def scrape_data():
    log("ğŸš€ Báº®T Äáº¦U QUÃ‰T CHá»¢ Tá»T - Nháº¡c cá»¥ HÃ  Ná»™i â‰¤ 2.1tr")
    worksheet = connect_google_sheet()
    
    # Äá»c dá»¯ liá»‡u hiá»‡n táº¡i
    try:
        all_values = worksheet.get_all_values()
        existing_data = all_values[1:] if len(all_values) > 1 else []
        
        # Táº¡o map: link â†’ row number
        link_to_row = {}
        # Táº¡o set: cÃ¡c title Ä‘Ã£ tá»“n táº¡i (Ä‘á»ƒ check trÃ¹ng title)
        existing_titles = set()
        # Táº¡o map: title â†’ list row numbers (náº¿u title trÃ¹ng nhiá»u)
        title_to_rows = {}
        
        for i, row in enumerate(existing_data, start=2):
            if len(row) >= 4:
                link = row[3].strip() if len(row) > 3 else ""
                title = row[1].strip() if len(row) > 1 else ""
                
                if link:
                    link_to_row[link] = i
                if title:
                    existing_titles.add(title)
                    if title not in title_to_rows:
                        title_to_rows[title] = []
                    title_to_rows[title].append(i)
        
        existing_links = set(link_to_row.keys())
        log(f"Äá»c {len(existing_links)} tin cÅ© | {len(existing_titles)} title khÃ¡c nhau tá»« sheet")
    except Exception as e:
        log(f"Lá»—i Ä‘á»c sheet: {e}")
        existing_links = set()
        existing_titles = set()
        link_to_row = {}
        title_to_rows = {}
    
    driver = setup_driver()
    total_new = 0
    total_updated = 0
    page = 1
    consecutive_empty = 0
    global_stt_counter = 1
    page_stt_logs = []
    batch_updates = []
    new_rows = []
    
    while page <= MAX_PAGES:
        url = START_URL if page == 1 else f"{START_URL}&page={page}"
        log(f"Trang {page} â†’ {url}")
        
        try:
            driver.get(url)
            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, "li.a14axl8t")))
        except Exception as e:
            log(f"Load trang {page} lá»—i: {e}")
            if page_has_no_results(driver):
                break
            consecutive_empty += 1
            if consecutive_empty >= MAX_CONSECUTIVE_EMPTY:
                break
            page += 1
            time.sleep(SLEEP_BETWEEN_PAGES)
            continue
        
        if page_has_no_results(driver):
            break
        
        items = driver.find_elements(By.CSS_SELECTOR, "li.a14axl8t")
        log(f"Trang {page}: TÃ¬m tháº¥y {len(items)} tin")
        page_stt_start = global_stt_counter
        page_item_count = 0
        
        for item_el in items:
            data = extract_item_data(item_el, page)
            if not data:
                continue
            
            link = data["link"]
            title = data["title"]
            page_item_count += 1
            current_stt = global_stt_counter
            global_stt_counter += 1
            
            row_data = [
                str(current_stt),
                title,
                data["price"],
                link,
                data["time"],
                data["location"],
                data["seller"],
                str(data["views"]),
                str(page)
            ]
            
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            # Logic má»›i: Chá»‰ check tin má»›i á»Ÿ trang 1
            # Chá»‰ gá»­i Telegram náº¿u Cáº¢ title VÃ€ link Ä‘á»u KHÃ”NG trÃ¹ng
            # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if page == 1:
                title_exists = title in existing_titles
                link_exists = link in existing_links
                
                if link_exists:
                    # Link Ä‘Ã£ tá»“n táº¡i â†’ tin cÅ© â†’ update STT/Views/Hidden
                    row_num = link_to_row[link]
                    batch_updates.append({"range": f"A{row_num}", "values": [[str(current_stt)]]})
                    batch_updates.append({"range": f"H{row_num}", "values": [[str(data["views"])]]})
                    batch_updates.append({"range": f"I{row_num}", "values": [[str(page)]]})
                    total_updated += 1
                    log(f"Trang 1 - Update tin cÅ© (link trÃ¹ng): {title[:40]}...")
                
                elif title_exists:
                    # Title trÃ¹ng nhÆ°ng link má»›i â†’ KHÃ”NG coi lÃ  má»›i, KHÃ”NG gá»­i Telegram
                    # NhÆ°ng váº«n thÃªm vÃ o sheet nhÆ° tin má»›i (vÃ¬ link khÃ¡c)
                    new_rows.append(row_data)
                    total_new += 1
                    existing_links.add(link)
                    existing_titles.add(title)  # Cáº­p nháº­t set title
                    log(f"Trang 1 - Title trÃ¹ng nhÆ°ng link má»›i (khÃ´ng gá»­i Tele): {title[:40]}...")
                
                else:
                    # Cáº£ title VÃ€ link Ä‘á»u khÃ´ng trÃ¹ng â†’ TIN Má»šI â†’ gá»­i Telegram
                    images = get_images_from_detail(link)
                    send_telegram_with_media(data, images)
                    new_rows.append(row_data)
                    total_new += 1
                    existing_links.add(link)
                    existing_titles.add(title)
                    log(f"Trang 1 - TIN Má»šI (title + link má»›i) â†’ Gá»­i Tele: {title[:40]}...")
            
            else:
                # Trang >=2: chá»‰ update náº¿u link Ä‘Ã£ tá»“n táº¡i (khÃ´ng check title, khÃ´ng gá»­i Tele)
                if link in existing_links:
                    row_num = link_to_row[link]
                    batch_updates.append({"range": f"A{row_num}", "values": [[str(current_stt)]]})
                    batch_updates.append({"range": f"H{row_num}", "values": [[str(data["views"])]]})
                    batch_updates.append({"range": f"I{row_num}", "values": [[str(page)]]})
                    total_updated += 1
                    log(f"Trang {page} - Update tin cÅ©: {title[:40]}...")
        
        if page_item_count > 0:
            page_stt_logs.append(
                f"Trang {page}: {page_item_count} tin, STT tá»« {page_stt_start} â†’ {global_stt_counter-1}"
            )
        else:
            page_stt_logs.append(f"Trang {page}: KhÃ´ng cÃ³ tin nÃ o")
        
        if page_item_count == 0:
            consecutive_empty += 1
        else:
            consecutive_empty = 0
        
        page += 1
        time.sleep(SLEEP_BETWEEN_PAGES)
    
    driver.quit()
    
    # Log thá»‘ng kÃª
    log("=== THá»NG KÃŠ ÄÃNH STT THEO Tá»ªNG TRANG ===")
    for log_line in page_stt_logs:
        log(log_line)
    log(f"Tá»•ng STT Ä‘Ã£ Ä‘Ã¡nh: 1 â†’ {global_stt_counter-1}")
    
    # Batch update tin cÅ©
    if batch_updates:
        try:
            worksheet.batch_update(batch_updates)
            log(f"ÄÃ£ batch update {len(batch_updates)//3} tin cÅ© (STT + Views + Hidden)")
        except Exception as e:
            log(f"Lá»—i batch update: {e}")
    
    # Append tin má»›i (chá»‰ tá»« trang 1, vÃ  Ä‘Ã£ lá»c theo logic title+link)
    if new_rows:
        try:
            worksheet.append_rows(new_rows)
            log(f"ÄÃ£ thÃªm {len(new_rows)} tin má»›i vÃ o sheet")
        except Exception as e:
            log(f"Lá»—i append rows: {e}")
    
    # Sort láº¡i toÃ n bá»™ sheet
    log("Báº¯t Ä‘áº§u sáº¯p xáº¿p láº¡i toÃ n bá»™ sheet...")
    try:
        all_data = worksheet.get_all_values()
        if len(all_data) <= 1:
            log("Sheet trá»‘ng hoáº·c chá»‰ cÃ³ header â†’ bá» qua sort")
        else:
            header = all_data[0]
            data_rows = all_data[1:]
            sorted_rows = sorted(
                data_rows,
                key=lambda row: (
                    int(row[8]) if row[8].isdigit() else 999999 if row[8] == "Hidden" else 0,
                    int(row[0]) if row[0].isdigit() else 999999
                )
            )
            worksheet.clear()
            worksheet.append_row(header)
            worksheet.append_rows(sorted_rows)
            log(f"ÄÃ£ sort láº¡i {len(sorted_rows)} dÃ²ng (Page â†‘ â†’ STT â†‘)")
    except Exception as e:
        log(f"Lá»—i khi sort sheet: {e}")
    
    log(f"HoÃ n thÃ nh: +{total_new} má»›i | â†‘{total_updated} cáº­p nháº­t | Tá»•ng STT cuá»‘i: {global_stt_counter-1}")

if __name__ == "__main__":
    try:
        scrape_data()
    except Exception as e:
        log(f"Lá»—i chÃ­nh: {e}")
